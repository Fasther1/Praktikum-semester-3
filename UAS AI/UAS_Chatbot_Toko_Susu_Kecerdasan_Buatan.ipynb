{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CybXxtkjSvqo",
        "outputId": "f62896ca-6532-4413-88cc-4eb0074efdf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall tflearn\n",
        "!pip install git+https://github.com/MihaMarkic/tflearn.git@fix/is_sequence_missing -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCdeJ4RRTC1K",
        "outputId": "177a8795-a4bc-4bae-ce33-f4321c88f72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "import numpy\n",
        "import tflearn\n",
        "import tensorflow\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6uchzoJbZLp",
        "outputId": "acff9c37-a9bc-4ff6-ba17-83eadc9db5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FbRV4hy0autw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('intents.json') as file:\n",
        "    data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x8a08Z5gXDhr"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "labels = []\n",
        "docs_x = []\n",
        "docs_y = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7UzafYcBXQZA"
      },
      "outputs": [],
      "source": [
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        wrds = nltk.word_tokenize(pattern)\n",
        "        words.extend(wrds)\n",
        "        docs_x.append(wrds)\n",
        "        docs_y.append(intent[\"tag\"])\n",
        "\n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xwMvmlvkXTi0"
      },
      "outputs": [],
      "source": [
        "words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "labels = sorted(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FDlIt0WiXcgI"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for x, doc in enumerate(docs_x):\n",
        "    bag = []\n",
        "\n",
        "    wrds = [stemmer.stem(w.lower()) for w in doc]\n",
        "\n",
        "    for w in words:\n",
        "        if w in wrds:\n",
        "            bag.append(1)\n",
        "        else:\n",
        "            bag.append(0)\n",
        "\n",
        "    output_row = out_empty[:]\n",
        "    output_row[labels.index(docs_y[x])] = 1\n",
        "\n",
        "    training.append(bag)\n",
        "    output.append(output_row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q2i9d2YUXf7V"
      },
      "outputs": [],
      "source": [
        "training = numpy.array(training)\n",
        "output = numpy.array(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IGaRqzdUyA2",
        "outputId": "5a92d9cd-8dca-4389-9930-23db30527380"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YSMOth-JbxRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f288e683-d35d-48cb-c113-128fe6eff267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tflearn/initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "ops.reset_default_graph()\n",
        "\n",
        "net = tflearn.input_data(shape=[None, len(training[0])])\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, 8)\n",
        "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "model = tflearn.DNN(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJSp1NJ0Vgdi",
        "outputId": "c6950754-7059-49d5-892a-13750de91e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Step: 17199  | total loss: \u001b[1m\u001b[32m0.07491\u001b[0m\u001b[0m | time: 0.040s\n",
            "| Adam | epoch: 1720 | loss: 0.07491 - acc: 0.9808 -- iter: 72/74\n",
            "Training Step: 17200  | total loss: \u001b[1m\u001b[32m0.06755\u001b[0m\u001b[0m | time: 0.044s\n",
            "| Adam | epoch: 1720 | loss: 0.06755 - acc: 0.9827 -- iter: 74/74\n",
            "--\n"
          ]
        }
      ],
      "source": [
        "model.fit(training, output, n_epoch=1020, batch_size=8, show_metric=True)\n",
        "model.save(\"/content/modelpaing.tflearn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeBi10m3b6Ai"
      },
      "outputs": [],
      "source": [
        "# try:\n",
        "#     model.load(\"/content/model.tflearn\")\n",
        "# except:\n",
        "#     model.fit(training, output, n_epoch=100, batch_size=8, show_metric=True)\n",
        "#     model.save(\"/content/model.tflearn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TEOVCUcuZEAv"
      },
      "outputs": [],
      "source": [
        "model.load(\"/content/modelpaing.tflearn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcslkK8HcgKF",
        "outputId": "ffff077d-f09b-45b7-a4cc-42980bf6ec70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with the bot (type quit to stop)!\n",
            "You: Bisakah saya membayar dengan kartu kredit?\n",
            "Anda dapat membayar dengan berbagai metode pembayaran, seperti kartu kredit, kartu debit, uang tunai, dan transfer bank.\n",
            "You: Bisakah saya memberikan saran atau masukan?\n",
            "Jika Anda tidak puas dengan produk atau layanan kami, Anda dapat memberikan komplain melalui email, telepon, atau media sosial. Kami akan berusaha untuk menyelesaikan masalah Anda dengan cepat dan tepat.\n",
            "You: Apa saja produk yang sedang diskon?\n",
            "Ya, saat ini kami sedang ada diskon untuk produk susu tertentu. Silakan kunjungi website kami untuk melihat informasi lebih lanjut.\n",
            "You: see you later\n",
            "Sampai jumpa lagi! Senang bisa membantu Anda.\n",
            "You: Bisakah saya pesan online?\n",
            "Ya, Anda dapat memesan produk susu secara online melalui website kami.\n",
            "You: Apakah Anda menggunakan bahan-bahan organik?\n",
            "Ya, semua produk kami diproduksi dengan standar keamanan yang tinggi. Kami memastikan bahwa semua produk kami aman untuk dikonsumsi.\n",
            "You: Berapa harga susu sapi?\n",
            "Harga susu ini adalah Rp. X.000.\n",
            "You: quit\n"
          ]
        }
      ],
      "source": [
        "def bag_of_words(s, words):\n",
        "    bag = [0 for _ in range(len(words))]\n",
        "\n",
        "    s_words = nltk.word_tokenize(s)\n",
        "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
        "\n",
        "    for se in s_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == se:\n",
        "                bag[i] = 1\n",
        "\n",
        "    return numpy.array(bag)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    print(\"Start talking with the bot (type quit to stop)!\")\n",
        "    while True:\n",
        "        inp = input(\"You: \")\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        results = model.predict([bag_of_words(inp, words)])\n",
        "        results_index = numpy.argmax(results)\n",
        "        tag = labels[results_index]\n",
        "\n",
        "        for tg in data[\"intents\"]:\n",
        "            if tg['tag'] == tag:\n",
        "                responses = tg['responses']\n",
        "\n",
        "        print(random.choice(responses))\n",
        "\n",
        "chat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg8XN40R9qoB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}